{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["G2kUkp0VKVOu"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"id":"s_rzhd2zuTHS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730716767297,"user_tz":-120,"elapsed":276,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}},"outputId":"2a06c3b9-8a6c-4c7a-e611-dc760f4ac181"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7df71b67a870>"]},"metadata":{},"execution_count":35}],"source":["import numpy as np\n","\n","from tqdm import tqdm, trange\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam, SGD\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","\n","from torchvision import transforms\n","from torchvision.datasets.cifar import CIFAR10\n","\n","np.random.seed(0)\n","torch.manual_seed(0)"]},{"cell_type":"code","source":[],"metadata":{"id":"r54vQpolZzKw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classes"],"metadata":{"id":"m9D22ICNKS2l"}},{"cell_type":"code","source":["class Patcher(nn.Module):\n","  def __init__(self, patch_size):\n","    super(Patcher, self).__init__()\n","    self.patch_size=patch_size\n","    self.unfold = torch.nn.Unfold(kernel_size=patch_size, stride=patch_size)\n","\n","  def forward(self, images):\n","    batch_size, channels, height, width = images.shape\n","    patch_height, patch_width = [self.patch_size, self.patch_size]\n","    assert height % patch_height == 0 and width % patch_width == 0, \"Height and width must be divisible by the patch size.\"\n","\n","    patches = self.unfold(images) #bs (cxpxp) N\n","    patches = patches.view(batch_size, channels, patch_height, patch_width, -1).permute(0, 4, 1, 2, 3) # bs N C P P\n","\n","    return patches"],"metadata":{"id":"jyawBF6HuWdi","executionInfo":{"status":"ok","timestamp":1730716213284,"user_tz":-120,"elapsed":30,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, model_dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.norm1 = nn.LayerNorm(model_dim)\n","        self.attn = nn.MultiheadAttention(model_dim, num_heads, dropout=dropout)\n","        self.norm2 = nn.LayerNorm(model_dim)\n","\n","        # Feedforward network\n","        self.mlp = nn.Sequential(\n","            nn.Linear(model_dim, int(model_dim * mlp_ratio)),\n","            nn.GELU(),\n","            nn.Linear(int(model_dim * mlp_ratio), model_dim),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        # Self-attention\n","        x = self.norm1(x)\n","        attn_out, _ = self.attn(x, x, x)\n","        x = x + attn_out\n","\n","        # Feedforward network\n","        x = self.norm2(x)\n","        mlp_out = self.mlp(x)\n","        x = x + mlp_out\n","\n","        return x"],"metadata":{"id":"LzxO9EnOmn-P","executionInfo":{"status":"ok","timestamp":1730716213286,"user_tz":-120,"elapsed":23,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class ViT_RGB(nn.Module):\n","  def __init__(self, img_size, patch_size, model_dim= 30, num_heads=3, num_layers=2, n_classes=10):\n","    super().__init__()\n","    self.img_size = img_size\n","    self.patch_size = patch_size\n","    self.n_patches = (self.img_size // self.patch_size) ** 2\n","    self.model_dim = model_dim\n","    self.num_layers = num_layers\n","    self.num_heads= num_heads\n","    self.n_classes = n_classes\n","\n","    # 1) Patching\n","    self.patcher = Patcher(patch_size=self.patch_size)\n","\n","    # 2) Linear Prjection\n","    self.linear_projector = nn.Linear( 3 * self.patch_size ** 2, self.model_dim)\n","\n","    # 3) Class Token\n","    self.class_token = nn.Parameter(torch.rand(1, 1, self.model_dim)) # This common for all images! TODO\n","\n","    # 4) Positional Embedding\n","    self.positional_embedding = nn.Parameter(torch.rand(1,(img_size // patch_size) ** 2 + 1, model_dim))\n","\n","    # 5) Transformer blocks\n","    self.blocks = nn.ModuleList([\n","        TransformerBlock( self.model_dim,  self.num_heads) for _ in range(num_layers)\n","    ])\n","\n","    # 6) Classification MLPk\n","    self.mlp = nn.Sequential(\n","            nn.Linear(self.model_dim, self.n_classes),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","  def forward(self, x):\n","\n","    x = self.patcher(x)\n","\n","    x = x.flatten(start_dim=2)\n","    x = self.linear_projector(x)\n","\n","    batch_size = x.shape[0]\n","    class_token = self.class_token.expand(batch_size, -1, -1)\n","    x = torch.cat((class_token, x), dim=1)\n","\n","    x = x + self.positional_embedding\n","\n","    for block in self.blocks:\n","      x = block(x)\n","\n","    latent = x[:, 0]\n","    # latent = x.mean(dim=1)\n","    logits = self.mlp(latent)\n","\n","    return logits, latent"],"metadata":{"id":"Gp7zZHXFN8qV","executionInfo":{"status":"ok","timestamp":1730721818358,"user_tz":-120,"elapsed":301,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["### Test Classes"],"metadata":{"id":"G2kUkp0VKVOu"}},{"cell_type":"code","source":["%pdb off\n","class ViTTester():\n","  def __init__(self):\n","    self.vit = ViT_RGB(img_size=32, patch_size=4, model_dim=20, num_heads=4, num_layers=3, n_classes=10)\n","\n","  def test(self):\n","    images = torch.randn(7, 3, 32, 32)\n","    tokens = self.vit(images)\n","    print(tokens[0].shape)\n","    return tokens\n","\n","tokens = ViTTester().test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvzHtDqIOcot","executionInfo":{"status":"ok","timestamp":1730712709253,"user_tz":-120,"elapsed":291,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}},"outputId":"909218f8-193e-40ae-bda3-dd370cb040bb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Automatic pdb calling has been turned OFF\n","torch.Size([7, 10])\n"]}]},{"cell_type":"code","source":["!wget https://picsum.photos/32 -O image.jpg"],"metadata":{"id":"b_p2B7OOG14d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import numpy as np\n","\n","class PatcherTester():\n","  def __init__(self, image_path, patch_size):\n","    self.patcher = Patcher(patch_size)\n","    self.image_path = image_path\n","\n","  def plot_original(self):\n","    img_src = self.image_path\n","    image = Image.open(img_src)\n","    return image\n","\n","  def plot_patches(self):\n","    img_src = self.image_path\n","    image = Image.open(img_src)\n","    image = np.array(image)\n","    image = image.astype('float32') / 255.0  # Normalize to [0, 1]\n","    image = torch.from_numpy(image)\n","    image = image.permute(2,0,1)\n","    image = image.unsqueeze(0) #to add the batch dimension\n","    p = self.patcher(image)\n","    p = p.squeeze()\n","    fig = plt.figure(figsize=(8, 8))\n","    grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.1)\n","    for i, ax in enumerate(grid):\n","        patch = p[i].permute(1, 2, 0).numpy()\n","        ax.imshow(patch)\n","        ax.axis('off')\n","    plt.show()"],"metadata":{"id":"azGllEEBEfMy","executionInfo":{"status":"ok","timestamp":1730720486053,"user_tz":-120,"elapsed":644,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["patcher = PatcherTester(\"./image.jpg\", 75)\n","patcher.plot_original()"],"metadata":{"id":"SecCIlY0Ghxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patcher = PatcherTester(\"./image.jpg\", 4)\n","patcher.plot_patches()"],"metadata":{"id":"L6j6DSeDIb4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"-U48kuNxrKTm"}},{"cell_type":"code","source":["del model\n","torch.cuda.empty_cache()"],"metadata":{"id":"YVYGA66STKDV","executionInfo":{"status":"ok","timestamp":1730721822772,"user_tz":-120,"elapsed":322,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ViT_RGB(img_size=32, patch_size=4, model_dim=100, num_heads=4, num_layers=3, n_classes=10).to(device)"],"metadata":{"id":"-DswvQgcPQFI","executionInfo":{"status":"ok","timestamp":1730721823539,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["transform_train = transforms.Compose([\n","    # transforms.RandomCrop(32, padding=4),\n","    transforms.Resize(32),\n","    # transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(32),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","train_set = CIFAR10(root='./datasets', train=True, download=True, transform=transform_train)\n","test_set = CIFAR10(root='./datasets', train=False, download=True, transform=transform_test)\n","\n","train_loader = DataLoader(train_set, shuffle=True, batch_size=64)\n","test_loader = DataLoader(test_set, shuffle=False, batch_size=64)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EizpTTcLlrte","executionInfo":{"status":"ok","timestamp":1730721827066,"user_tz":-120,"elapsed":1831,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}},"outputId":"b8a87784-9e74-47a2-c352-841f05d436f1"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["n_epochs = 200\n","lr = 0.0001\n","\n","optimizer = Adam(model.parameters(), lr=lr)\n","criterion = CrossEntropyLoss()\n","\n","for epoch in range(n_epochs):\n","    train_loss = 0.0\n","    for i,batch in enumerate(train_loader):\n","        x, y = batch\n","        x, y = x.to(device), y.to(device)\n","        y_hat, latent = model(x)\n","        loss = criterion(y_hat, y)\n","\n","        batch_loss = loss.detach().cpu().item()\n","        train_loss += batch_loss / len(train_loader)\n","\n","        optimizer.zero_grad()\n","        cls0 = model.class_token.clone()\n","        loss.backward()\n","        optimizer.step()\n","        cls1 = model.class_token.clone()\n","\n","        # if((cls0 == cls1).sum()):\n","        #   print(\"cls==\")\n","        #   break\n","\n","        if i%100==0:\n","          print(f\"Batch {i}/{len(train_loader)} loss: {batch_loss:.03f}\")\n","\n","    print(f\"Epoch {epoch + 1}/{n_epochs} loss: {train_loss:.03f}\")"],"metadata":{"id":"SzkYBarsrNFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test loop\n","with torch.no_grad():\n","    correct, total = 0, 0\n","    test_loss = 0.0\n","    for batch in tqdm(test_loader, desc=\"Testing\"):\n","        x, y = batch\n","        x, y = x.to(device), y.to(device)\n","        y_hat, latent = model(x)\n","        loss = criterion(y_hat, y)\n","        test_loss += loss.detach().cpu().item() / len(test_loader)\n","\n","        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n","        total += len(x)\n","    print(f\"Test loss: {test_loss:.2f}\")\n","    print(f\"Test accuracy: {correct / total * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4NwNDn2wdCT","executionInfo":{"status":"ok","timestamp":1730721768488,"user_tz":-120,"elapsed":4880,"user":{"displayName":"Ahmad Mustapha","userId":"16876350814210984474"}},"outputId":"dc8decfa-f49b-4143-e01a-6ca1db945506"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing: 100%|██████████| 157/157 [00:04<00:00, 34.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Test loss: 1.78\n","Test accuracy: 68.15%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}